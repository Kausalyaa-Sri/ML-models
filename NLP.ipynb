{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Sentence:Lifestyle is a way used by people, groups and nations and is formed in specific geographical, economic, political, cultural and religious text. Lifestyle is referred to the characteristics of inhabitants of a region in special time and place. It includes day to day behaviors and functions of individuals in job, activities, fun and diet.  In recent decades, life style as an important factor of health is more interested by researchers. According to WHO, 60% of related factors to individual health and quality of life are correlated to lifestyle (1). Millions of people follow an unhealthy lifestyle. Hence, they encounter illness, disability and even death. Problems like metabolic diseases, joint and skeletal problems, cardio-vascular diseases, hypertension, overweight, violence and so on, can be caused by an unhealthy lifestyle. The relationship of lifestyle and health should be highly considered.  Today, wide changes have occurred in life of all people. Malnutrition, unhealthy diet, smoking, alcohol consuming, drug abuse, stress and so on, are the presentations of unhealthy life style that they are used as dominant form of lifestyle. Besides, the lives of citizens face with new challenges. For instance, emerging new technologies within IT such as the internet and virtual communication networks, lead our world to a major challenge that threatens the physical and mental health of individuals. The challenge is the overuse and misuse of the technology.\n"
     ]
    }
   ],
   "source": [
    "user_input=input(\"Enter Sentence:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence=sent_tokenize(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lifestyle',\n",
       " 'is',\n",
       " 'a',\n",
       " 'way',\n",
       " 'used',\n",
       " 'by',\n",
       " 'people',\n",
       " ',',\n",
       " 'groups',\n",
       " 'and',\n",
       " 'nations',\n",
       " 'and',\n",
       " 'is',\n",
       " 'formed',\n",
       " 'in',\n",
       " 'specific',\n",
       " 'geographical',\n",
       " ',',\n",
       " 'economic',\n",
       " ',',\n",
       " 'political',\n",
       " ',',\n",
       " 'cultural',\n",
       " 'and',\n",
       " 'religious',\n",
       " 'text',\n",
       " '.',\n",
       " 'Lifestyle',\n",
       " 'is',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'the',\n",
       " 'characteristics',\n",
       " 'of',\n",
       " 'inhabitants',\n",
       " 'of',\n",
       " 'a',\n",
       " 'region',\n",
       " 'in',\n",
       " 'special',\n",
       " 'time',\n",
       " 'and',\n",
       " 'place',\n",
       " '.',\n",
       " 'It',\n",
       " 'includes',\n",
       " 'day',\n",
       " 'to',\n",
       " 'day',\n",
       " 'behaviors',\n",
       " 'and',\n",
       " 'functions',\n",
       " 'of',\n",
       " 'individuals',\n",
       " 'in',\n",
       " 'job',\n",
       " ',',\n",
       " 'activities',\n",
       " ',',\n",
       " 'fun',\n",
       " 'and',\n",
       " 'diet',\n",
       " '.',\n",
       " 'In',\n",
       " 'recent',\n",
       " 'decades',\n",
       " ',',\n",
       " 'life',\n",
       " 'style',\n",
       " 'as',\n",
       " 'an',\n",
       " 'important',\n",
       " 'factor',\n",
       " 'of',\n",
       " 'health',\n",
       " 'is',\n",
       " 'more',\n",
       " 'interested',\n",
       " 'by',\n",
       " 'researchers',\n",
       " '.',\n",
       " 'According',\n",
       " 'to',\n",
       " 'WHO',\n",
       " ',',\n",
       " '60',\n",
       " '%',\n",
       " 'of',\n",
       " 'related',\n",
       " 'factors',\n",
       " 'to',\n",
       " 'individual',\n",
       " 'health',\n",
       " 'and',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'life',\n",
       " 'are',\n",
       " 'correlated',\n",
       " 'to',\n",
       " 'lifestyle',\n",
       " '(',\n",
       " '1',\n",
       " ')',\n",
       " '.',\n",
       " 'Millions',\n",
       " 'of',\n",
       " 'people',\n",
       " 'follow',\n",
       " 'an',\n",
       " 'unhealthy',\n",
       " 'lifestyle',\n",
       " '.',\n",
       " 'Hence',\n",
       " ',',\n",
       " 'they',\n",
       " 'encounter',\n",
       " 'illness',\n",
       " ',',\n",
       " 'disability',\n",
       " 'and',\n",
       " 'even',\n",
       " 'death',\n",
       " '.',\n",
       " 'Problems',\n",
       " 'like',\n",
       " 'metabolic',\n",
       " 'diseases',\n",
       " ',',\n",
       " 'joint',\n",
       " 'and',\n",
       " 'skeletal',\n",
       " 'problems',\n",
       " ',',\n",
       " 'cardio-vascular',\n",
       " 'diseases',\n",
       " ',',\n",
       " 'hypertension',\n",
       " ',',\n",
       " 'overweight',\n",
       " ',',\n",
       " 'violence',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " ',',\n",
       " 'can',\n",
       " 'be',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'an',\n",
       " 'unhealthy',\n",
       " 'lifestyle',\n",
       " '.',\n",
       " 'The',\n",
       " 'relationship',\n",
       " 'of',\n",
       " 'lifestyle',\n",
       " 'and',\n",
       " 'health',\n",
       " 'should',\n",
       " 'be',\n",
       " 'highly',\n",
       " 'considered',\n",
       " '.',\n",
       " 'Today',\n",
       " ',',\n",
       " 'wide',\n",
       " 'changes',\n",
       " 'have',\n",
       " 'occurred',\n",
       " 'in',\n",
       " 'life',\n",
       " 'of',\n",
       " 'all',\n",
       " 'people',\n",
       " '.',\n",
       " 'Malnutrition',\n",
       " ',',\n",
       " 'unhealthy',\n",
       " 'diet',\n",
       " ',',\n",
       " 'smoking',\n",
       " ',',\n",
       " 'alcohol',\n",
       " 'consuming',\n",
       " ',',\n",
       " 'drug',\n",
       " 'abuse',\n",
       " ',',\n",
       " 'stress',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " ',',\n",
       " 'are',\n",
       " 'the',\n",
       " 'presentations',\n",
       " 'of',\n",
       " 'unhealthy',\n",
       " 'life',\n",
       " 'style',\n",
       " 'that',\n",
       " 'they',\n",
       " 'are',\n",
       " 'used',\n",
       " 'as',\n",
       " 'dominant',\n",
       " 'form',\n",
       " 'of',\n",
       " 'lifestyle',\n",
       " '.',\n",
       " 'Besides',\n",
       " ',',\n",
       " 'the',\n",
       " 'lives',\n",
       " 'of',\n",
       " 'citizens',\n",
       " 'face',\n",
       " 'with',\n",
       " 'new',\n",
       " 'challenges',\n",
       " '.',\n",
       " 'For',\n",
       " 'instance',\n",
       " ',',\n",
       " 'emerging',\n",
       " 'new',\n",
       " 'technologies',\n",
       " 'within',\n",
       " 'IT',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'and',\n",
       " 'virtual',\n",
       " 'communication',\n",
       " 'networks',\n",
       " ',',\n",
       " 'lead',\n",
       " 'our',\n",
       " 'world',\n",
       " 'to',\n",
       " 'a',\n",
       " 'major',\n",
       " 'challenge',\n",
       " 'that',\n",
       " 'threatens',\n",
       " 'the',\n",
       " 'physical',\n",
       " 'and',\n",
       " 'mental',\n",
       " 'health',\n",
       " 'of',\n",
       " 'individuals',\n",
       " '.',\n",
       " 'The',\n",
       " 'challenge',\n",
       " 'is',\n",
       " 'the',\n",
       " 'overuse',\n",
       " 'and',\n",
       " 'misuse',\n",
       " 'of',\n",
       " 'the',\n",
       " 'technology',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words=word_tokenize(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('English')  #these are called stopwords wich r not actully required for the machine to find out the intend of the sentence we are giving as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords=stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us now remove the stopwords from tokenized words\n",
    "clean_words=[]\n",
    "for each in tokenized_words:\n",
    "    if not each.lower() in list_stopwords:\n",
    "        clean_words.append(each)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 177)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_words),len(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()  #find the root words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('writing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifestyle ---> lifestyl\n",
      "is ---> is\n",
      "a ---> a\n",
      "way ---> way\n",
      "used ---> use\n",
      "by ---> by\n",
      "people ---> peopl\n",
      ", ---> ,\n",
      "groups ---> group\n",
      "and ---> and\n",
      "nations ---> nation\n",
      "and ---> and\n",
      "is ---> is\n",
      "formed ---> form\n",
      "in ---> in\n",
      "specific ---> specif\n",
      "geographical ---> geograph\n",
      ", ---> ,\n",
      "economic ---> econom\n",
      ", ---> ,\n",
      "political ---> polit\n",
      ", ---> ,\n",
      "cultural ---> cultur\n",
      "and ---> and\n",
      "religious ---> religi\n",
      "text ---> text\n",
      ". ---> .\n",
      "Lifestyle ---> lifestyl\n",
      "is ---> is\n",
      "referred ---> refer\n",
      "to ---> to\n",
      "the ---> the\n",
      "characteristics ---> characterist\n",
      "of ---> of\n",
      "inhabitants ---> inhabit\n",
      "of ---> of\n",
      "a ---> a\n",
      "region ---> region\n",
      "in ---> in\n",
      "special ---> special\n",
      "time ---> time\n",
      "and ---> and\n",
      "place ---> place\n",
      ". ---> .\n",
      "It ---> It\n",
      "includes ---> includ\n",
      "day ---> day\n",
      "to ---> to\n",
      "day ---> day\n",
      "behaviors ---> behavior\n",
      "and ---> and\n",
      "functions ---> function\n",
      "of ---> of\n",
      "individuals ---> individu\n",
      "in ---> in\n",
      "job ---> job\n",
      ", ---> ,\n",
      "activities ---> activ\n",
      ", ---> ,\n",
      "fun ---> fun\n",
      "and ---> and\n",
      "diet ---> diet\n",
      ". ---> .\n",
      "In ---> In\n",
      "recent ---> recent\n",
      "decades ---> decad\n",
      ", ---> ,\n",
      "life ---> life\n",
      "style ---> style\n",
      "as ---> as\n",
      "an ---> an\n",
      "important ---> import\n",
      "factor ---> factor\n",
      "of ---> of\n",
      "health ---> health\n",
      "is ---> is\n",
      "more ---> more\n",
      "interested ---> interest\n",
      "by ---> by\n",
      "researchers ---> research\n",
      ". ---> .\n",
      "According ---> accord\n",
      "to ---> to\n",
      "WHO ---> who\n",
      ", ---> ,\n",
      "60 ---> 60\n",
      "% ---> %\n",
      "of ---> of\n",
      "related ---> relat\n",
      "factors ---> factor\n",
      "to ---> to\n",
      "individual ---> individu\n",
      "health ---> health\n",
      "and ---> and\n",
      "quality ---> qualiti\n",
      "of ---> of\n",
      "life ---> life\n",
      "are ---> are\n",
      "correlated ---> correl\n",
      "to ---> to\n",
      "lifestyle ---> lifestyl\n",
      "( ---> (\n",
      "1 ---> 1\n",
      ") ---> )\n",
      ". ---> .\n",
      "Millions ---> million\n",
      "of ---> of\n",
      "people ---> peopl\n",
      "follow ---> follow\n",
      "an ---> an\n",
      "unhealthy ---> unhealthi\n",
      "lifestyle ---> lifestyl\n",
      ". ---> .\n",
      "Hence ---> henc\n",
      ", ---> ,\n",
      "they ---> they\n",
      "encounter ---> encount\n",
      "illness ---> ill\n",
      ", ---> ,\n",
      "disability ---> disabl\n",
      "and ---> and\n",
      "even ---> even\n",
      "death ---> death\n",
      ". ---> .\n",
      "Problems ---> problem\n",
      "like ---> like\n",
      "metabolic ---> metabol\n",
      "diseases ---> diseas\n",
      ", ---> ,\n",
      "joint ---> joint\n",
      "and ---> and\n",
      "skeletal ---> skelet\n",
      "problems ---> problem\n",
      ", ---> ,\n",
      "cardio-vascular ---> cardio-vascular\n",
      "diseases ---> diseas\n",
      ", ---> ,\n",
      "hypertension ---> hypertens\n",
      ", ---> ,\n",
      "overweight ---> overweight\n",
      ", ---> ,\n",
      "violence ---> violenc\n",
      "and ---> and\n",
      "so ---> so\n",
      "on ---> on\n",
      ", ---> ,\n",
      "can ---> can\n",
      "be ---> be\n",
      "caused ---> caus\n",
      "by ---> by\n",
      "an ---> an\n",
      "unhealthy ---> unhealthi\n",
      "lifestyle ---> lifestyl\n",
      ". ---> .\n",
      "The ---> the\n",
      "relationship ---> relationship\n",
      "of ---> of\n",
      "lifestyle ---> lifestyl\n",
      "and ---> and\n",
      "health ---> health\n",
      "should ---> should\n",
      "be ---> be\n",
      "highly ---> highli\n",
      "considered ---> consid\n",
      ". ---> .\n",
      "Today ---> today\n",
      ", ---> ,\n",
      "wide ---> wide\n",
      "changes ---> chang\n",
      "have ---> have\n",
      "occurred ---> occur\n",
      "in ---> in\n",
      "life ---> life\n",
      "of ---> of\n",
      "all ---> all\n",
      "people ---> peopl\n",
      ". ---> .\n",
      "Malnutrition ---> malnutrit\n",
      ", ---> ,\n",
      "unhealthy ---> unhealthi\n",
      "diet ---> diet\n",
      ", ---> ,\n",
      "smoking ---> smoke\n",
      ", ---> ,\n",
      "alcohol ---> alcohol\n",
      "consuming ---> consum\n",
      ", ---> ,\n",
      "drug ---> drug\n",
      "abuse ---> abus\n",
      ", ---> ,\n",
      "stress ---> stress\n",
      "and ---> and\n",
      "so ---> so\n",
      "on ---> on\n",
      ", ---> ,\n",
      "are ---> are\n",
      "the ---> the\n",
      "presentations ---> present\n",
      "of ---> of\n",
      "unhealthy ---> unhealthi\n",
      "life ---> life\n",
      "style ---> style\n",
      "that ---> that\n",
      "they ---> they\n",
      "are ---> are\n",
      "used ---> use\n",
      "as ---> as\n",
      "dominant ---> domin\n",
      "form ---> form\n",
      "of ---> of\n",
      "lifestyle ---> lifestyl\n",
      ". ---> .\n",
      "Besides ---> besid\n",
      ", ---> ,\n",
      "the ---> the\n",
      "lives ---> live\n",
      "of ---> of\n",
      "citizens ---> citizen\n",
      "face ---> face\n",
      "with ---> with\n",
      "new ---> new\n",
      "challenges ---> challeng\n",
      ". ---> .\n",
      "For ---> for\n",
      "instance ---> instanc\n",
      ", ---> ,\n",
      "emerging ---> emerg\n",
      "new ---> new\n",
      "technologies ---> technolog\n",
      "within ---> within\n",
      "IT ---> IT\n",
      "such ---> such\n",
      "as ---> as\n",
      "the ---> the\n",
      "internet ---> internet\n",
      "and ---> and\n",
      "virtual ---> virtual\n",
      "communication ---> commun\n",
      "networks ---> network\n",
      ", ---> ,\n",
      "lead ---> lead\n",
      "our ---> our\n",
      "world ---> world\n",
      "to ---> to\n",
      "a ---> a\n",
      "major ---> major\n",
      "challenge ---> challeng\n",
      "that ---> that\n",
      "threatens ---> threaten\n",
      "the ---> the\n",
      "physical ---> physic\n",
      "and ---> and\n",
      "mental ---> mental\n",
      "health ---> health\n",
      "of ---> of\n",
      "individuals ---> individu\n",
      ". ---> .\n",
      "The ---> the\n",
      "challenge ---> challeng\n",
      "is ---> is\n",
      "the ---> the\n",
      "overuse ---> overus\n",
      "and ---> and\n",
      "misuse ---> misus\n",
      "of ---> of\n",
      "the ---> the\n",
      "technology ---> technolog\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "for each in tokenized_words:\n",
    "    print(each,\"--->\",ps.stem(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()  #lemmetizers and stemmers are used for the same purpose of finding the root words but their work fassion differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemetizers analyzes on the grammer of the words while the stemmers works on rules like (istead of ly,ion,s replace someting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'always'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"always\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifestyle ---> Lifestyle\n",
      "is ---> is\n",
      "a ---> a\n",
      "way ---> way\n",
      "used ---> used\n",
      "by ---> by\n",
      "people ---> people\n",
      ", ---> ,\n",
      "groups ---> group\n",
      "and ---> and\n",
      "nations ---> nation\n",
      "and ---> and\n",
      "is ---> is\n",
      "formed ---> formed\n",
      "in ---> in\n",
      "specific ---> specific\n",
      "geographical ---> geographical\n",
      ", ---> ,\n",
      "economic ---> economic\n",
      ", ---> ,\n",
      "political ---> political\n",
      ", ---> ,\n",
      "cultural ---> cultural\n",
      "and ---> and\n",
      "religious ---> religious\n",
      "text ---> text\n",
      ". ---> .\n",
      "Lifestyle ---> Lifestyle\n",
      "is ---> is\n",
      "referred ---> referred\n",
      "to ---> to\n",
      "the ---> the\n",
      "characteristics ---> characteristic\n",
      "of ---> of\n",
      "inhabitants ---> inhabitant\n",
      "of ---> of\n",
      "a ---> a\n",
      "region ---> region\n",
      "in ---> in\n",
      "special ---> special\n",
      "time ---> time\n",
      "and ---> and\n",
      "place ---> place\n",
      ". ---> .\n",
      "It ---> It\n",
      "includes ---> includes\n",
      "day ---> day\n",
      "to ---> to\n",
      "day ---> day\n",
      "behaviors ---> behavior\n",
      "and ---> and\n",
      "functions ---> function\n",
      "of ---> of\n",
      "individuals ---> individual\n",
      "in ---> in\n",
      "job ---> job\n",
      ", ---> ,\n",
      "activities ---> activity\n",
      ", ---> ,\n",
      "fun ---> fun\n",
      "and ---> and\n",
      "diet ---> diet\n",
      ". ---> .\n",
      "In ---> In\n",
      "recent ---> recent\n",
      "decades ---> decade\n",
      ", ---> ,\n",
      "life ---> life\n",
      "style ---> style\n",
      "as ---> a\n",
      "an ---> an\n",
      "important ---> important\n",
      "factor ---> factor\n",
      "of ---> of\n",
      "health ---> health\n",
      "is ---> is\n",
      "more ---> more\n",
      "interested ---> interested\n",
      "by ---> by\n",
      "researchers ---> researcher\n",
      ". ---> .\n",
      "According ---> According\n",
      "to ---> to\n",
      "WHO ---> WHO\n",
      ", ---> ,\n",
      "60 ---> 60\n",
      "% ---> %\n",
      "of ---> of\n",
      "related ---> related\n",
      "factors ---> factor\n",
      "to ---> to\n",
      "individual ---> individual\n",
      "health ---> health\n",
      "and ---> and\n",
      "quality ---> quality\n",
      "of ---> of\n",
      "life ---> life\n",
      "are ---> are\n",
      "correlated ---> correlated\n",
      "to ---> to\n",
      "lifestyle ---> lifestyle\n",
      "( ---> (\n",
      "1 ---> 1\n",
      ") ---> )\n",
      ". ---> .\n",
      "Millions ---> Millions\n",
      "of ---> of\n",
      "people ---> people\n",
      "follow ---> follow\n",
      "an ---> an\n",
      "unhealthy ---> unhealthy\n",
      "lifestyle ---> lifestyle\n",
      ". ---> .\n",
      "Hence ---> Hence\n",
      ", ---> ,\n",
      "they ---> they\n",
      "encounter ---> encounter\n",
      "illness ---> illness\n",
      ", ---> ,\n",
      "disability ---> disability\n",
      "and ---> and\n",
      "even ---> even\n",
      "death ---> death\n",
      ". ---> .\n",
      "Problems ---> Problems\n",
      "like ---> like\n",
      "metabolic ---> metabolic\n",
      "diseases ---> disease\n",
      ", ---> ,\n",
      "joint ---> joint\n",
      "and ---> and\n",
      "skeletal ---> skeletal\n",
      "problems ---> problem\n",
      ", ---> ,\n",
      "cardio-vascular ---> cardio-vascular\n",
      "diseases ---> disease\n",
      ", ---> ,\n",
      "hypertension ---> hypertension\n",
      ", ---> ,\n",
      "overweight ---> overweight\n",
      ", ---> ,\n",
      "violence ---> violence\n",
      "and ---> and\n",
      "so ---> so\n",
      "on ---> on\n",
      ", ---> ,\n",
      "can ---> can\n",
      "be ---> be\n",
      "caused ---> caused\n",
      "by ---> by\n",
      "an ---> an\n",
      "unhealthy ---> unhealthy\n",
      "lifestyle ---> lifestyle\n",
      ". ---> .\n",
      "The ---> The\n",
      "relationship ---> relationship\n",
      "of ---> of\n",
      "lifestyle ---> lifestyle\n",
      "and ---> and\n",
      "health ---> health\n",
      "should ---> should\n",
      "be ---> be\n",
      "highly ---> highly\n",
      "considered ---> considered\n",
      ". ---> .\n",
      "Today ---> Today\n",
      ", ---> ,\n",
      "wide ---> wide\n",
      "changes ---> change\n",
      "have ---> have\n",
      "occurred ---> occurred\n",
      "in ---> in\n",
      "life ---> life\n",
      "of ---> of\n",
      "all ---> all\n",
      "people ---> people\n",
      ". ---> .\n",
      "Malnutrition ---> Malnutrition\n",
      ", ---> ,\n",
      "unhealthy ---> unhealthy\n",
      "diet ---> diet\n",
      ", ---> ,\n",
      "smoking ---> smoking\n",
      ", ---> ,\n",
      "alcohol ---> alcohol\n",
      "consuming ---> consuming\n",
      ", ---> ,\n",
      "drug ---> drug\n",
      "abuse ---> abuse\n",
      ", ---> ,\n",
      "stress ---> stress\n",
      "and ---> and\n",
      "so ---> so\n",
      "on ---> on\n",
      ", ---> ,\n",
      "are ---> are\n",
      "the ---> the\n",
      "presentations ---> presentation\n",
      "of ---> of\n",
      "unhealthy ---> unhealthy\n",
      "life ---> life\n",
      "style ---> style\n",
      "that ---> that\n",
      "they ---> they\n",
      "are ---> are\n",
      "used ---> used\n",
      "as ---> a\n",
      "dominant ---> dominant\n",
      "form ---> form\n",
      "of ---> of\n",
      "lifestyle ---> lifestyle\n",
      ". ---> .\n",
      "Besides ---> Besides\n",
      ", ---> ,\n",
      "the ---> the\n",
      "lives ---> life\n",
      "of ---> of\n",
      "citizens ---> citizen\n",
      "face ---> face\n",
      "with ---> with\n",
      "new ---> new\n",
      "challenges ---> challenge\n",
      ". ---> .\n",
      "For ---> For\n",
      "instance ---> instance\n",
      ", ---> ,\n",
      "emerging ---> emerging\n",
      "new ---> new\n",
      "technologies ---> technology\n",
      "within ---> within\n",
      "IT ---> IT\n",
      "such ---> such\n",
      "as ---> a\n",
      "the ---> the\n",
      "internet ---> internet\n",
      "and ---> and\n",
      "virtual ---> virtual\n",
      "communication ---> communication\n",
      "networks ---> network\n",
      ", ---> ,\n",
      "lead ---> lead\n",
      "our ---> our\n",
      "world ---> world\n",
      "to ---> to\n",
      "a ---> a\n",
      "major ---> major\n",
      "challenge ---> challenge\n",
      "that ---> that\n",
      "threatens ---> threatens\n",
      "the ---> the\n",
      "physical ---> physical\n",
      "and ---> and\n",
      "mental ---> mental\n",
      "health ---> health\n",
      "of ---> of\n",
      "individuals ---> individual\n",
      ". ---> .\n",
      "The ---> The\n",
      "challenge ---> challenge\n",
      "is ---> is\n",
      "the ---> the\n",
      "overuse ---> overuse\n",
      "and ---> and\n",
      "misuse ---> misuse\n",
      "of ---> of\n",
      "the ---> the\n",
      "technology ---> technology\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "for each in tokenized_words:\n",
    "    print(each,\"--->\",lemma.lemmatize(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lifestyle', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('used', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " (',', ','),\n",
       " ('groups', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('nations', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('is', 'VBZ'),\n",
       " ('formed', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('specific', 'JJ'),\n",
       " ('geographical', 'JJ'),\n",
       " (',', ','),\n",
       " ('economic', 'JJ'),\n",
       " (',', ','),\n",
       " ('political', 'JJ'),\n",
       " (',', ','),\n",
       " ('cultural', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('religious', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Lifestyle', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('referred', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('characteristics', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('inhabitants', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('region', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('special', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('place', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('includes', 'VBZ'),\n",
       " ('day', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('day', 'NN'),\n",
       " ('behaviors', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('functions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('individuals', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('job', 'NN'),\n",
       " (',', ','),\n",
       " ('activities', 'NNS'),\n",
       " (',', ','),\n",
       " ('fun', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('diet', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('recent', 'JJ'),\n",
       " ('decades', 'NNS'),\n",
       " (',', ','),\n",
       " ('life', 'NN'),\n",
       " ('style', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('factor', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('health', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('more', 'RBR'),\n",
       " ('interested', 'JJ'),\n",
       " ('by', 'IN'),\n",
       " ('researchers', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('According', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('WHO', 'NNP'),\n",
       " (',', ','),\n",
       " ('60', 'CD'),\n",
       " ('%', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('related', 'JJ'),\n",
       " ('factors', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('individual', 'JJ'),\n",
       " ('health', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('quality', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('correlated', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('lifestyle', 'VB'),\n",
       " ('(', '('),\n",
       " ('1', 'CD'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('Millions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('follow', 'VBP'),\n",
       " ('an', 'DT'),\n",
       " ('unhealthy', 'JJ'),\n",
       " ('lifestyle', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Hence', 'NNP'),\n",
       " (',', ','),\n",
       " ('they', 'PRP'),\n",
       " ('encounter', 'VBP'),\n",
       " ('illness', 'NN'),\n",
       " (',', ','),\n",
       " ('disability', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('even', 'RB'),\n",
       " ('death', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Problems', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('metabolic', 'JJ'),\n",
       " ('diseases', 'NNS'),\n",
       " (',', ','),\n",
       " ('joint', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('skeletal', 'JJ'),\n",
       " ('problems', 'NNS'),\n",
       " (',', ','),\n",
       " ('cardio-vascular', 'JJ'),\n",
       " ('diseases', 'NNS'),\n",
       " (',', ','),\n",
       " ('hypertension', 'NN'),\n",
       " (',', ','),\n",
       " ('overweight', 'NN'),\n",
       " (',', ','),\n",
       " ('violence', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('on', 'IN'),\n",
       " (',', ','),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('caused', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('unhealthy', 'JJ'),\n",
       " ('lifestyle', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('relationship', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('lifestyle', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('health', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('highly', 'RB'),\n",
       " ('considered', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('Today', 'NN'),\n",
       " (',', ','),\n",
       " ('wide', 'JJ'),\n",
       " ('changes', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('occurred', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('life', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Malnutrition', 'NNP'),\n",
       " (',', ','),\n",
       " ('unhealthy', 'JJ'),\n",
       " ('diet', 'NN'),\n",
       " (',', ','),\n",
       " ('smoking', 'NN'),\n",
       " (',', ','),\n",
       " ('alcohol', 'NN'),\n",
       " ('consuming', 'NN'),\n",
       " (',', ','),\n",
       " ('drug', 'NN'),\n",
       " ('abuse', 'NN'),\n",
       " (',', ','),\n",
       " ('stress', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('on', 'IN'),\n",
       " (',', ','),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('presentations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('unhealthy', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('style', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('used', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('dominant', 'JJ'),\n",
       " ('form', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('lifestyle', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Besides', 'IN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('lives', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('citizens', 'NNS'),\n",
       " ('face', 'VBP'),\n",
       " ('with', 'IN'),\n",
       " ('new', 'JJ'),\n",
       " ('challenges', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('instance', 'NN'),\n",
       " (',', ','),\n",
       " ('emerging', 'VBG'),\n",
       " ('new', 'JJ'),\n",
       " ('technologies', 'NNS'),\n",
       " ('within', 'IN'),\n",
       " ('IT', 'NNP'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('internet', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('virtual', 'JJ'),\n",
       " ('communication', 'NN'),\n",
       " ('networks', 'NNS'),\n",
       " (',', ','),\n",
       " ('lead', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('world', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('major', 'JJ'),\n",
       " ('challenge', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('threatens', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('physical', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('mental', 'JJ'),\n",
       " ('health', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('individuals', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('challenge', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('overuse', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('misuse', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('technology', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(tokenized_words)  #gives the grammatical part of the word, google search for the abbreviations of pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 12:01:01 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:46 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:15 -0800</td>\n",
       "      <td>Nigeria,lagos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:02 -0800</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:58:51 -0800</td>\n",
       "      <td>dallas, TX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513           neutral                        1.0000   \n",
       "1      570301130888122368          positive                        0.3486   \n",
       "2      570301083672813571           neutral                        0.6837   \n",
       "3      570301031407624196          negative                        1.0000   \n",
       "4      570300817074462722          negative                        1.0000   \n",
       "...                   ...               ...                           ...   \n",
       "14635  569587686496825344          positive                        0.3487   \n",
       "14636  569587371693355008          negative                        1.0000   \n",
       "14637  569587242672398336           neutral                        1.0000   \n",
       "14638  569587188687634433          negative                        1.0000   \n",
       "14639  569587140490866689           neutral                        0.6771   \n",
       "\n",
       "               negativereason  negativereason_confidence         airline  \\\n",
       "0                         NaN                        NaN  Virgin America   \n",
       "1                         NaN                     0.0000  Virgin America   \n",
       "2                         NaN                        NaN  Virgin America   \n",
       "3                  Bad Flight                     0.7033  Virgin America   \n",
       "4                  Can't Tell                     1.0000  Virgin America   \n",
       "...                       ...                        ...             ...   \n",
       "14635                     NaN                     0.0000        American   \n",
       "14636  Customer Service Issue                     1.0000        American   \n",
       "14637                     NaN                        NaN        American   \n",
       "14638  Customer Service Issue                     0.6659        American   \n",
       "14639                     NaN                     0.0000        American   \n",
       "\n",
       "      airline_sentiment_gold             name negativereason_gold  \\\n",
       "0                        NaN          cairdin                 NaN   \n",
       "1                        NaN         jnardino                 NaN   \n",
       "2                        NaN       yvonnalynn                 NaN   \n",
       "3                        NaN         jnardino                 NaN   \n",
       "4                        NaN         jnardino                 NaN   \n",
       "...                      ...              ...                 ...   \n",
       "14635                    NaN  KristenReenders                 NaN   \n",
       "14636                    NaN         itsropes                 NaN   \n",
       "14637                    NaN         sanyabun                 NaN   \n",
       "14638                    NaN       SraJackson                 NaN   \n",
       "14639                    NaN        daviddtwu                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0                @VirginAmerica What @dhepburn said.   \n",
       "1                  0  @VirginAmerica plus you've added commercials t...   \n",
       "2                  0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                  0  @VirginAmerica it's really aggressive to blast...   \n",
       "4                  0  @VirginAmerica and it's a really big bad thing...   \n",
       "...              ...                                                ...   \n",
       "14635              0  @AmericanAir thank you we got on a different f...   \n",
       "14636              0  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637              0  @AmericanAir Please bring American Airlines to...   \n",
       "14638              0  @AmericanAir you have my money, you change my ...   \n",
       "14639              0  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "      tweet_coord              tweet_created tweet_location  \\\n",
       "0             NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1             NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2             NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3             NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4             NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "...           ...                        ...            ...   \n",
       "14635         NaN  2015-02-22 12:01:01 -0800            NaN   \n",
       "14636         NaN  2015-02-22 11:59:46 -0800          Texas   \n",
       "14637         NaN  2015-02-22 11:59:15 -0800  Nigeria,lagos   \n",
       "14638         NaN  2015-02-22 11:59:02 -0800     New Jersey   \n",
       "14639         NaN  2015-02-22 11:58:51 -0800     dallas, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0      Eastern Time (US & Canada)  \n",
       "1      Pacific Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4      Pacific Time (US & Canada)  \n",
       "...                           ...  \n",
       "14635                         NaN  \n",
       "14636                         NaN  \n",
       "14637                         NaN  \n",
       "14638  Eastern Time (US & Canada)  \n",
       "14639                         NaN  \n",
       "\n",
       "[14640 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['airline_sentiment','airline_sentiment_confidence','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  airline_sentiment_confidence  \\\n",
       "0               neutral                        1.0000   \n",
       "1              positive                        0.3486   \n",
       "2               neutral                        0.6837   \n",
       "3              negative                        1.0000   \n",
       "4              negative                        1.0000   \n",
       "...                 ...                           ...   \n",
       "14635          positive                        0.3487   \n",
       "14636          negative                        1.0000   \n",
       "14637           neutral                        1.0000   \n",
       "14638          negative                        1.0000   \n",
       "14639           neutral                        0.6771   \n",
       "\n",
       "                                                    text  \n",
       "0                    @VirginAmerica What @dhepburn said.  \n",
       "1      @VirginAmerica plus you've added commercials t...  \n",
       "2      @VirginAmerica I didn't today... Must mean I n...  \n",
       "3      @VirginAmerica it's really aggressive to blast...  \n",
       "4      @VirginAmerica and it's a really big bad thing...  \n",
       "...                                                  ...  \n",
       "14635  @AmericanAir thank you we got on a different f...  \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...  \n",
       "14637  @AmericanAir Please bring American Airlines to...  \n",
       "14638  @AmericanAir you have my money, you change my ...  \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantweet_list=[]\n",
    "airlines=['virginamerica','jetblue','americanair','united','usaieways']\n",
    "spl_charaters=['!','@','#','$','%','^','&','*',':)']\n",
    "for i in range (df.shape[0]):\n",
    "    current_tweet=df['text'].values[i]\n",
    "    list_of_words=word_tokenize(current_tweet)\n",
    "    cleantweet=''\n",
    "    for each in list_of_words:\n",
    "        each=each.lower()\n",
    "        if not each in list_stopwords:\n",
    "            if not each in airlines:\n",
    "                if not each in spl_charaters:\n",
    "                    cleantweet=cleantweet+' '+each\n",
    "            \n",
    "    cleantweet_list.append(cleantweet) \n",
    "   #cleaning the data by removing spl char, repeated words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-0fb4f32b6357>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_tweet']=cleantweet_list\n"
     ]
    }
   ],
   "source": [
    "df['clean_tweet']=cleantweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>dhepburn said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>plus 've added commercials experience ... tac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>n't today ... must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>'s really aggressive blast obnoxious `` enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>'s really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>seriously would pay 30 flight seats n't playi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>yes , nearly every time fly vx “ ear worm ” ’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>really missed prime opportunity men without h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>well , didn't…but : -d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>amazing , arrived hour early . 're good .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>know suicide second leading cause death among...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>lt ; 3 pretty graphics . much better minimal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>great deal already thinking 2nd trip australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>virginmedia 'm flying fabulous seductive skie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>sfo-pdx schedule still mia .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>excited first cross country flight lax mco 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>flew nyc sfo last week could n't fully sit se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>I ❤️ flying @VirginAmerica. ☺️👍</td>\n",
       "      <td>❤️ flying . ☺️👍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>know would amazingly awesome ? bos-fll please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>@VirginAmerica why are your first fares in May...</td>\n",
       "      <td>first fares may three times carriers seats av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.c...</td>\n",
       "      <td>love graphic . http : //t.co/ut5grrwaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica I love the hipster innovation. ...</td>\n",
       "      <td>love hipster innovation . feel good brand .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica will you be making BOS&amp;gt;LAS n...</td>\n",
       "      <td>making bos gt ; las non stop permanently anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica you guys messed up my seating.....</td>\n",
       "      <td>guys messed seating .. reserved seating frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica status match program.  I applie...</td>\n",
       "      <td>status match program . applied 's three weeks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What happened 2 ur vegan food o...</td>\n",
       "      <td>happened 2 ur vegan food options ? least say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>@VirginAmerica do you miss me? Don't worry we'...</td>\n",
       "      <td>miss ? n't worry 'll together soon .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica amazing to me that we can't get...</td>\n",
       "      <td>amazing ca n't get cold air vents . vx358 noa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>@VirginAmerica LAX to EWR - Middle seat on a r...</td>\n",
       "      <td>lax ewr - middle seat red eye . noob maneuver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica hi! I just bked a cool birthday...</td>\n",
       "      <td>hi bked cool birthday trip , ca n't add eleva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica Are the hours of operation for ...</td>\n",
       "      <td>hours operation club sfo posted online current ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica help, left expensive headphones...</td>\n",
       "      <td>help , left expensive headphones flight 89 ia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica awaiting my return phone call, ...</td>\n",
       "      <td>awaiting return phone call , would prefer use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica this is great news!  America co...</td>\n",
       "      <td>great news america could start flights hawaii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>Nice RT @VirginAmerica: Vibe with the moodligh...</td>\n",
       "      <td>nice rt : vibe moodlight takeoff touchdown . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica Moodlighting is the only way to...</td>\n",
       "      <td>moodlighting way fly best experience ever coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica @freddieawards Done and done! B...</td>\n",
       "      <td>freddieawards done done best airline around ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>@VirginAmerica when can I book my flight to Ha...</td>\n",
       "      <td>book flight hawaii ? ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica Your chat support is not workin...</td>\n",
       "      <td>chat support working site : http : //t.co/vhp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6639</td>\n",
       "      <td>@VirginAmerica View of downtown Los Angeles, t...</td>\n",
       "      <td>view downtown los angeles , hollywood sign , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6688</td>\n",
       "      <td>@VirginAmerica Hey, first time flyer next week...</td>\n",
       "      <td>hey , first time flyer next week - excited 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica plz help me win my bid upgrade ...</td>\n",
       "      <td>plz help win bid upgrade flight 2/27 lax -- -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>@VirginAmerica I have an unused ticket but mov...</td>\n",
       "      <td>unused ticket moved new city n't fly . fly ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica are flights leaving Dallas for ...</td>\n",
       "      <td>flights leaving dallas seattle time feb 24 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica I'm #elevategold for a good rea...</td>\n",
       "      <td>'m elevategold good reason : rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>@VirginAmerica  DREAM http://t.co/oA2dRfAoQ2 h...</td>\n",
       "      <td>dream http : //t.co/oa2drfaoq2 http : //t.co/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica wow this just blew my mind</td>\n",
       "      <td>wow blew mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica @ladygaga @carrieunderwood Afte...</td>\n",
       "      <td>ladygaga carrieunderwood last night tribute s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>@VirginAmerica @ladygaga @carrieunderwood All ...</td>\n",
       "      <td>ladygaga carrieunderwood entertaining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline_sentiment  airline_sentiment_confidence  \\\n",
       "0                   1                        1.0000   \n",
       "1                   2                        0.3486   \n",
       "2                   1                        0.6837   \n",
       "3                   0                        1.0000   \n",
       "4                   0                        1.0000   \n",
       "5                   0                        1.0000   \n",
       "6                   2                        0.6745   \n",
       "7                   1                        0.6340   \n",
       "8                   2                        0.6559   \n",
       "9                   2                        1.0000   \n",
       "10                  1                        0.6769   \n",
       "11                  2                        1.0000   \n",
       "12                  2                        1.0000   \n",
       "13                  2                        0.6451   \n",
       "14                  2                        1.0000   \n",
       "15                  0                        0.6842   \n",
       "16                  2                        1.0000   \n",
       "17                  0                        1.0000   \n",
       "18                  2                        1.0000   \n",
       "19                  2                        1.0000   \n",
       "20                  0                        0.6705   \n",
       "21                  2                        1.0000   \n",
       "22                  2                        1.0000   \n",
       "23                  1                        1.0000   \n",
       "24                  0                        1.0000   \n",
       "25                  0                        1.0000   \n",
       "26                  0                        1.0000   \n",
       "27                  1                        0.6854   \n",
       "28                  0                        1.0000   \n",
       "29                  1                        0.6150   \n",
       "30                  0                        1.0000   \n",
       "31                  1                        1.0000   \n",
       "32                  0                        1.0000   \n",
       "33                  0                        1.0000   \n",
       "34                  2                        1.0000   \n",
       "35                  1                        0.6207   \n",
       "36                  2                        1.0000   \n",
       "37                  2                        1.0000   \n",
       "38                  1                        0.6791   \n",
       "39                  0                        1.0000   \n",
       "40                  2                        0.6639   \n",
       "41                  0                        0.6688   \n",
       "42                  1                        1.0000   \n",
       "43                  1                        0.6578   \n",
       "44                  1                        1.0000   \n",
       "45                  2                        1.0000   \n",
       "46                  1                        0.6799   \n",
       "47                  2                        1.0000   \n",
       "48                  1                        1.0000   \n",
       "49                  1                        0.6436   \n",
       "\n",
       "                                                 text  \\\n",
       "0                 @VirginAmerica What @dhepburn said.   \n",
       "1   @VirginAmerica plus you've added commercials t...   \n",
       "2   @VirginAmerica I didn't today... Must mean I n...   \n",
       "3   @VirginAmerica it's really aggressive to blast...   \n",
       "4   @VirginAmerica and it's a really big bad thing...   \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...   \n",
       "6   @VirginAmerica yes, nearly every time I fly VX...   \n",
       "7   @VirginAmerica Really missed a prime opportuni...   \n",
       "8     @virginamerica Well, I didn't…but NOW I DO! :-D   \n",
       "9   @VirginAmerica it was amazing, and arrived an ...   \n",
       "10  @VirginAmerica did you know that suicide is th...   \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...   \n",
       "12  @VirginAmerica This is such a great deal! Alre...   \n",
       "13  @VirginAmerica @virginmedia I'm flying your #f...   \n",
       "14                             @VirginAmerica Thanks!   \n",
       "15      @VirginAmerica SFO-PDX schedule is still MIA.   \n",
       "16  @VirginAmerica So excited for my first cross c...   \n",
       "17  @VirginAmerica  I flew from NYC to SFO last we...   \n",
       "18                    I ❤️ flying @VirginAmerica. ☺️👍   \n",
       "19  @VirginAmerica you know what would be amazingl...   \n",
       "20  @VirginAmerica why are your first fares in May...   \n",
       "21  @VirginAmerica I love this graphic. http://t.c...   \n",
       "22  @VirginAmerica I love the hipster innovation. ...   \n",
       "23  @VirginAmerica will you be making BOS&gt;LAS n...   \n",
       "24  @VirginAmerica you guys messed up my seating.....   \n",
       "25  @VirginAmerica status match program.  I applie...   \n",
       "26  @VirginAmerica What happened 2 ur vegan food o...   \n",
       "27  @VirginAmerica do you miss me? Don't worry we'...   \n",
       "28  @VirginAmerica amazing to me that we can't get...   \n",
       "29  @VirginAmerica LAX to EWR - Middle seat on a r...   \n",
       "30  @VirginAmerica hi! I just bked a cool birthday...   \n",
       "31  @VirginAmerica Are the hours of operation for ...   \n",
       "32  @VirginAmerica help, left expensive headphones...   \n",
       "33  @VirginAmerica awaiting my return phone call, ...   \n",
       "34  @VirginAmerica this is great news!  America co...   \n",
       "35  Nice RT @VirginAmerica: Vibe with the moodligh...   \n",
       "36  @VirginAmerica Moodlighting is the only way to...   \n",
       "37  @VirginAmerica @freddieawards Done and done! B...   \n",
       "38  @VirginAmerica when can I book my flight to Ha...   \n",
       "39  @VirginAmerica Your chat support is not workin...   \n",
       "40  @VirginAmerica View of downtown Los Angeles, t...   \n",
       "41  @VirginAmerica Hey, first time flyer next week...   \n",
       "42  @VirginAmerica plz help me win my bid upgrade ...   \n",
       "43  @VirginAmerica I have an unused ticket but mov...   \n",
       "44  @VirginAmerica are flights leaving Dallas for ...   \n",
       "45  @VirginAmerica I'm #elevategold for a good rea...   \n",
       "46  @VirginAmerica  DREAM http://t.co/oA2dRfAoQ2 h...   \n",
       "47          @VirginAmerica wow this just blew my mind   \n",
       "48  @VirginAmerica @ladygaga @carrieunderwood Afte...   \n",
       "49  @VirginAmerica @ladygaga @carrieunderwood All ...   \n",
       "\n",
       "                                          clean_tweet  \n",
       "0                                     dhepburn said .  \n",
       "1    plus 've added commercials experience ... tac...  \n",
       "2      n't today ... must mean need take another trip  \n",
       "3    's really aggressive blast obnoxious `` enter...  \n",
       "4                             's really big bad thing  \n",
       "5    seriously would pay 30 flight seats n't playi...  \n",
       "6    yes , nearly every time fly vx “ ear worm ” ’...  \n",
       "7    really missed prime opportunity men without h...  \n",
       "8                              well , didn't…but : -d  \n",
       "9           amazing , arrived hour early . 're good .  \n",
       "10   know suicide second leading cause death among...  \n",
       "11   lt ; 3 pretty graphics . much better minimal ...  \n",
       "12   great deal already thinking 2nd trip australi...  \n",
       "13   virginmedia 'm flying fabulous seductive skie...  \n",
       "14                                             thanks  \n",
       "15                       sfo-pdx schedule still mia .  \n",
       "16   excited first cross country flight lax mco 'v...  \n",
       "17   flew nyc sfo last week could n't fully sit se...  \n",
       "18                                    ❤️ flying . ☺️👍  \n",
       "19   know would amazingly awesome ? bos-fll please...  \n",
       "20   first fares may three times carriers seats av...  \n",
       "21            love graphic . http : //t.co/ut5grrwaaa  \n",
       "22        love hipster innovation . feel good brand .  \n",
       "23   making bos gt ; las non stop permanently anyt...  \n",
       "24   guys messed seating .. reserved seating frien...  \n",
       "25   status match program . applied 's three weeks...  \n",
       "26   happened 2 ur vegan food options ? least say ...  \n",
       "27               miss ? n't worry 'll together soon .  \n",
       "28   amazing ca n't get cold air vents . vx358 noa...  \n",
       "29   lax ewr - middle seat red eye . noob maneuver...  \n",
       "30   hi bked cool birthday trip , ca n't add eleva...  \n",
       "31   hours operation club sfo posted online current ?  \n",
       "32   help , left expensive headphones flight 89 ia...  \n",
       "33   awaiting return phone call , would prefer use...  \n",
       "34   great news america could start flights hawaii...  \n",
       "35   nice rt : vibe moodlight takeoff touchdown . ...  \n",
       "36   moodlighting way fly best experience ever coo...  \n",
       "37   freddieawards done done best airline around ,...  \n",
       "38                             book flight hawaii ? ?  \n",
       "39   chat support working site : http : //t.co/vhp...  \n",
       "40   view downtown los angeles , hollywood sign , ...  \n",
       "41   hey , first time flyer next week - excited 'm...  \n",
       "42   plz help win bid upgrade flight 2/27 lax -- -...  \n",
       "43   unused ticket moved new city n't fly . fly ex...  \n",
       "44       flights leaving dallas seattle time feb 24 ?  \n",
       "45                  'm elevategold good reason : rock  \n",
       "46   dream http : //t.co/oa2drfaoq2 http : //t.co/...  \n",
       "47                                      wow blew mind  \n",
       "48   ladygaga carrieunderwood last night tribute s...  \n",
       "49              ladygaga carrieunderwood entertaining  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(df['clean_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=cv.transform(df['clean_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14640x14991 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 138578 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-d57a805fd8f0>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['airline_sentiment']=le.fit_transform(df['airline_sentiment'])\n"
     ]
    }
   ],
   "source": [
    "df['airline_sentiment']=le.fit_transform(df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>dhepburn said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>plus 've added commercials experience ... tac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>n't today ... must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>'s really aggressive blast obnoxious `` enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>'s really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>thank got different flight chicago .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>leaving 20 minutes late flight . warnings com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>please bring american airlines blackberry10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>money , change flight , n't answer phones sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>8 ppl need 2 know many seats next flight . pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_sentiment  airline_sentiment_confidence  \\\n",
       "0                      1                        1.0000   \n",
       "1                      2                        0.3486   \n",
       "2                      1                        0.6837   \n",
       "3                      0                        1.0000   \n",
       "4                      0                        1.0000   \n",
       "...                  ...                           ...   \n",
       "14635                  2                        0.3487   \n",
       "14636                  0                        1.0000   \n",
       "14637                  1                        1.0000   \n",
       "14638                  0                        1.0000   \n",
       "14639                  1                        0.6771   \n",
       "\n",
       "                                                    text  \\\n",
       "0                    @VirginAmerica What @dhepburn said.   \n",
       "1      @VirginAmerica plus you've added commercials t...   \n",
       "2      @VirginAmerica I didn't today... Must mean I n...   \n",
       "3      @VirginAmerica it's really aggressive to blast...   \n",
       "4      @VirginAmerica and it's a really big bad thing...   \n",
       "...                                                  ...   \n",
       "14635  @AmericanAir thank you we got on a different f...   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637  @AmericanAir Please bring American Airlines to...   \n",
       "14638  @AmericanAir you have my money, you change my ...   \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                                             clean_tweet  \n",
       "0                                        dhepburn said .  \n",
       "1       plus 've added commercials experience ... tac...  \n",
       "2         n't today ... must mean need take another trip  \n",
       "3       's really aggressive blast obnoxious `` enter...  \n",
       "4                                's really big bad thing  \n",
       "...                                                  ...  \n",
       "14635               thank got different flight chicago .  \n",
       "14636   leaving 20 minutes late flight . warnings com...  \n",
       "14637        please bring american airlines blackberry10  \n",
       "14638   money , change flight , n't answer phones sug...  \n",
       "14639   8 ppl need 2 know many seats next flight . pl...  \n",
       "\n",
       "[14640 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(matrix,df['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=nv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7584699453551913"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to note- here the encoding is done like negative sentence=0, neutral sentence=1, positive sentence=2\n",
    "# label encoding is done in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sen='the sun rises in the east'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_transformed_sen=cv.transform([user_sen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv.predict(user_transformed_sen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
